import requests
from bs4 import BeautifulSoup as bs   #将模块重命名
from concurrent.futures import ThreadPoolExecutor,wait
from lxml import etree
from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor #线程池，进程池
import threading,time

#headers头部里面需要加上close，否则开启太多会导致无法再建立新连接
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; LCTE; rv:11.0) like Gecko','Connection':'close'}

#多线程

#打开文件并按行读取

def urlport(i):
        #print(i)
    url = "https://open.unionpay.com:"+str(i)+"/" # 定义URL
    print(url)
    try:
        r = requests.get(url=url, headers=headers,timeout = 4)  # 请求目标网址
        soup=str(bs(r.content,'lxml'))  #利用BS解析网址,因为etree模块只识别字符串，所以需要转化
        page = etree.HTML(soup) #建立etree树
    #获取标题
        web_title = page.xpath("/html/head/title/text()")
    #xpath路径还可以通过浏览器中直接复制粘贴获取
        #web_keywords = page.xpath("//meta[@name='keywords']/@content")
        #web_description = page.xpath("//meta[@name='description']/@content")
        print(str(web_title) + url)
        with open('result.txt', 'a+') as r:  # result.txt里面存储的是批量解析后的结果
            r.write(line.strip('\n') + ' ')  # 显示有ip绑定的域名，用空格隔开
            r.write(url + '\n')
    except:
        with open('error.txt', 'a+') as r:  # result.txt里面存储的是批量解析后的结果
            r.write(url + ' ')  # 显示有ip绑定的域名，用空格隔开
            r.write("出现错误" + '\n')

if __name__ == '__main__':
    ports = [7,11,13,15,17,19,20,21,22,23,25,26,30,31,32,36,37,38,43,49,51,53, 53, 67,67, 69,70,79,80, 80,81,82,83,84,85,86,88, 88,89,98,102,104,110,111,113, 113,119,121, 123,135, 137,138,139,143, 161, 162,175,179,199,211,264,280,311,389, 391, 427,443, 443,444,445,449,465,500, 500,502,503,505,512,515, 520, 523,540,548,554,564,587,620, 623, 626,631,636,646,666, 705,771,777,789,800,801,808, 853,873,876,880,888,898,900,901,902,990,992,993,994,995,999,1000,1010,1022,1023,1024,1025,1026,1027, 1027,1042,1080,1099,1177,1194, 1194,1200,1201,1212,1214,1234,1241,1248,1260,1290,1302,1311,1314,1344,1400,1433, 1434,1443,1471,1494,1503,1505,1515,1521,1554,1588, 1604,1610, 1645, 1701,1720,1723,1741,1777, 1812,1830,1863,1880,1883, 1900,1901,1911,1935,1947,1962,1967,1991, 1993,2000,2001,2002,2010,2020,2022,2030,2049,2051,2052,2053,2055,2064,2077,2080,2082,2083, 2083,2086,2087, 2094,2095,2096,2121, 2123, 2152,2160,2181,2222,2223,2252,2306,2323,2332,2375,2376,2379,2396,2401,2404,2406, 2424,2424, 2425, 2427,2443,2455,2480,2501,2525,2600,2601,2628,2715,2809,2869,3000,3001,3002,3005,3050,3052,3075,3097,3128,3260,3280, 3283,3288,3299,3306,3307,3310,3311,3312,3333, 3333,3337,3352,3372,3388,3389,3390, 3391,3443,3460, 3478,3520,3522,3523,3524,3525,3528,3531,3541,3542, 3671,3689,3690, 3702,3749,3780, 3784,3790,4000,4022,4040, 4050,4063,4064, 4070,4155,4300,4369,4430,4433,4440,4443,4444, 4500,4505,4506,4567,4660,4664,4711,4712,4730,4782,4786, 4800,4840,4842,4848,4880,4911,4949,5000, 5000,5001, 5001,5002, 5002,5004, 5004,5005, 5005, 5006,5006, 5007,5007, 5008,5009,5038,5050, 5050,5051, 5060,5061, 5061,5084, 5093, 5094, 5095,5111,5222,5258,5269,5280, 5351, 5353,5357,5400,5427,5432,5443,5550, 5554,5555,5560,5577,5598,5601,5631, 5632,5672, 5673,5678, 5683,5800,5801,5802,5820,5900,5901,5902,5903,5938,5984,5985,5986,6000,6001, 6002,6002, 6003,6003, 6006,6006,6060, 6060,6068,6080,6082,6103,6346,6363,6379,6443,6488,6544,6560,6565,6581,6588,6590,6600,6664,6665,6666,6667,6668,6669,6697,6699,6780,6782, 6881, 6969,6998,7000, 7000,7001, 7001,7002,7003, 7003,7005, 7005,7007,7014,7070,7071,7077,7080,7100,7144,7145,7170,7171,7180,7187,7199,7272,7288,7401,7402,7443,7474,7479,7493,7537,7547,7548,7634,7657,7676,7776,7777,7778,7779,7780,7788,7911,8000,8001,8002, 8002,8003,8004,8005,8006,8007,8008,8009,8010,8020,8025,8030,8040,8058,8060,8069,8080,8081,8082,8083,8084,8085,8086,8087,8088,8089,8090,8091,8092,8093,8094,8095,8096,8097,8098,8099,8111,8112,8118,8123,8125,8126,8129,8138,8139,8140,8159,8161,8181,8182,8194,8200,8291,8332,8333,8334,8351,8377,8378,8388,8443,8444,8480,8500,8529,8545,8546,8554,8649,8686,8765,8800,8834,8880,8881,8882,8883,8884,8885,8886,8887,8888, 8888,8889,8890,8899,8983,8999,9000, 9000,9001,9002,9003,9009,9010,9030,9042,9050,9051,9080,9083,9090,9091,9100, 9100,9151,9191,9200,9292,9295,9300,9306,9333,9334,9418,9443,9444,9446,9527,9530,9595, 9600,9653,9668,9700,9711,9801,9864,9869,9870,9876,9943,9944,9981,9997,9999,10000,10001, 10001,10003,10005,10030,10035,10162,10243,10250,10255,10332,10333,10443,10554,11001,11211,11300,11310,11371,11965,12000,12300,12345,12999,13579,13666,13720,13722,14000,14147,14265,14443,14534,15000,16000,16010,16030,16922,16923,16992,16993,17000, 17185,17988,18000,18001,18080,18081,18086,18245,18246,18264,19150,19888,19999,20000, 20000,20332,20547,20880,22105,22222,22335,23023,23424,25000,25010,25105,25565,26214,26470, 27015,27015,27016,27017,28017,28080, 28784,29876,29999,30001, 30310, 30311, 30312, 30313, 30718,31337,32400, 32768,32770,32771,32773,33338,33890,34567,34599, 34962, 34963, 34964,37215,37777,40000,40001,41795,42873, 44818,45554, 47808, 48899,49151,49152,49153,49154,49155,50000,50050,50060,50070,50075,50090,50100,50111,51106,52869,55442,55553,55555, 59110,60001,60010,60030,60443,61613,61616,62078,64738]
    thread_pool = ThreadPoolExecutor(5) #定义5个线程执行此任务
    process_pool = ProcessPoolExecutor(5) #定义5个进程
    for u in ports:
        thread_pool.submit(urlport,u)

#counts = 0








    #data[0] = str(web_title)
    #data[counts][1] = str(web_keywords)
    #data[counts][2] = str(web_description)
    #counts = counts + 1
# 连接database
    #conn = pymysql.connect(host='127.0.0.1', user='root', password='root', database='dvwa', charset='utf8')




#print(data)

#soup = bs(r.content, 'lxml')  # 利用BS解析网址
#urls = soup.find_all(name='a', attrs={'data-click': re.compile(('.')), 'class': None})  # 利用bs提取标签为a，属性class为None的所有内容
#urls = soup.find_all(name='a', attrs={'data-click': re.compile(('.')), 'class': None})  # 利用bs提取标签为a，属性class为None的所有内容